# =============================================================================
# SGFA qMAP-PD DEBUG CONFIGURATION - OPTIMIZED FOR FAST TESTING
#
# This config provides minimal settings for rapid development and testing:
# üöÄ SPEED OPTIMIZATIONS:
#   - 50 MCMC samples (vs 2000 in production)
#   - 3 factors (vs 10 in production)
#   - No plots or intermediate saves
#   - Minimal preprocessing (no feature selection)
#   - 2 CV folds (vs 10 in production)
#   - CPU-only execution
#
# üß¨ PD SUBTYPE DISCOVERY FOCUS:
#   - Integrated SGFA performance + PD subtype discovery benchmarks
#   - Primary validation: pd_subtype_discovery (unsupervised clustering)
#   - Performance-discovery trade-off analysis
#   - Clinical translation metrics
#   - Multi-layer evaluation framework
#
# ‚è±Ô∏è  Expected runtime: ~1-2 minutes per experiment (vs 20-30 minutes)
# üéØ Use for: debugging, quick tests, CI/CD, PD subtype discovery development
# üìù Usage: python run_experiments.py --config config_debug.yaml
# =============================================================================

# Data Configuration - using synthetic data for speed
data:
  data_dir: "./qMAP-PD_data"              # Will fallback to synthetic if not found
  clinical_file: "data_clinical/clinical.tsv"
  volume_dir: "volume_matrices"
  imaging_as_single_view: true

# Experiment Configuration - minimal settings
experiments:
  base_output_dir: "./debug_results"      # Separate debug output
  save_intermediate: false                # Skip intermediate saves for speed
  generate_plots: false                   # Skip plots for speed
  max_parallel_jobs: 1                    # Single-threaded for easier debugging

# Model Configuration - minimal for fast execution
model:
  model_type: "sparse_gfa"
  K: 3                                    # Very small number of factors

  # MCMC Parameters - minimal for speed
  num_samples: 50                         # Very few samples
  num_warmup: 25                          # Minimal warmup
  num_chains: 1                           # Single chain

  # Sparsity Parameters
  sparsity_lambda: 0.1
  group_lambda: 0.1

  # Reproducibility
  random_seed: 42

# Preprocessing Configuration - MINIMAL FOR FAST TESTING
preprocessing:
  strategy: "minimal"                     # Fastest preprocessing strategy
  enable_advanced_preprocessing: false   # Skip advanced features for speed
  enable_spatial_processing: false       # Skip spatial processing
  imputation_strategy: "mean"            # Fastest imputation method
  feature_selection_method: "none"       # Skip feature selection for speed
  variance_threshold: 0.0                # Don't filter low-variance features
  missing_threshold: 1.0                 # Don't drop any features (keep all data)
  qc_outlier_threshold: null             # MAD filtering DISABLED (use --qc-outlier-threshold to enable)

# Cross-Validation Configuration - minimal CV
cross_validation:
  n_folds: 2                              # Minimal folds
  n_repeats: 1                            # Single repeat
  stratified: true
  group_aware: false
  random_seed: 42

# Monitoring Configuration
monitoring:
  checkpoint_dir: "./debug_results/checkpoints"
  log_level: "DEBUG"                      # Verbose logging for debugging
  save_checkpoints: false                 # Skip checkpoints for speed
  checkpoint_interval: 50

# System Configuration - CONSERVATIVE FOR TESTING
system:
  use_gpu: false                          # Use CPU for consistent debugging (no GPU variability)
  memory_limit_gb: 4.0                    # Conservative memory limit
  n_cpu_cores: 2                          # Limit CPU usage for reproducible timing

# =============================================================================
# DEBUG EXPERIMENT-SPECIFIC CONFIGURATIONS
# =============================================================================

# Data Validation Experiment - single strategy
data_validation:
  preprocessing_strategies:
    minimal:
      enable_advanced_preprocessing: false
      imputation_strategy: "mean"

    aggressive:
      enable_advanced_preprocessing: true
      enable_spatial_processing: true
      imputation_strategy: "knn"
      feature_selection_method: "variance"
      variance_threshold: 0.005

# Model Comparison Experiment - PD subtype discovery focused
model_comparison:
  models:
    - name: "sparse_gfa"
      n_factors: [3]                      # Single factor count
      sparsity_lambda: [0.1]              # Single sparsity level
      group_lambda: [0.1]

    - name: "standard_gfa"
      n_factors: [3]

  cross_validation:
    n_folds: 2
    n_repeats: 1

  evaluation_metrics:
    - "reconstruction_error"              # Traditional SGFA metric
    # - "subtype_discovery_quality"       # NOT YET IMPLEMENTED - placeholder for future
    # - "clinical_correlation"            # NOT YET IMPLEMENTED - placeholder for future

  # Comparative Benchmarks (moved from performance_benchmarks)
  comparative_benchmarks:
    baseline_methods: ["pca", "ica"]      # Limited for debug speed
    test_configurations:
      tiny_scale:
        n_subjects: 20
        n_features_per_view: 50
        n_views: 2
    comparison_metrics:
      - "execution_time"
      - "memory_usage"

# SGFA Hyperparameter Tuning Experiment - debug version
sgfa_configuration_comparison:
  parameter_ranges:
    n_factors: [20]                       # K = 20 only
    sparsity_lambda: [0.05, 0.1]          # Element-wise sparsity - two values only
    group_lambda: [0.0, 0.1]              # Group sparsity - two values for debug (0.0 = no group sparsity, higher = more shrinkage)
    learning_rate: [0.01]                 # Single value

  # Minimal Scalability Analysis for debug
  scalability_analysis:
    sample_size_ranges: [20, 30]          # Very small for debug
    feature_size_ranges: [50, 100]        # Small feature ranges
    component_ranges: [20]                # K = 20 only
    chain_ranges: [1]                     # Single chain only

    benchmark_configs:
      tiny_scale:
        n_subjects: 20
        n_features_per_view: [50, 30]     # Very small
      small_scale:
        n_subjects: 30
        n_features_per_view: [100, 80]

    scalability_metrics:
      - "training_time"
      - "memory_usage"

  stability_tests:
    n_random_inits: 2                     # Minimal random inits
    convergence_threshold: 1e-3           # Relaxed convergence

# Sensitivity Analysis Experiment - minimal parameter ranges
sensitivity_analysis:
  parameter_ranges:
    n_factors: [20]                       # K = 20 only
    sparsity_lambda: [0.05, 0.1]          # Two values only
    learning_rate: [0.01]                 # Single value

  stability_tests:
    n_random_inits: 2                     # Minimal random inits
    convergence_threshold: 1e-3           # Relaxed convergence

# Clinical Validation Experiment - PD subtype discovery focused
clinical_validation:
  validation_types:
    - "pd_subtype_discovery"              # Primary: unsupervised PD subtype discovery
    - "subtype_classification"            # Secondary: supervised classification (if labels available)

  classification_metrics:
    - "accuracy"                          # Basic metric for supervised validation

  # PD subtype discovery specific settings (NOT YET IMPLEMENTED - placeholder for future)
  # subtype_discovery_settings:
  #   max_subtypes: 4                       # Test 2-4 subtypes (common in PD research)
  #   clustering_methods: ["kmeans"]        # Just KMeans for debug speed
  #   stability_runs: 2                     # Minimal stability testing

  cross_validation:
    n_folds: 2                            # Minimal folds
    stratified: true

  # Integrated SGFA + Clinical Optimization (NOT YET IMPLEMENTED - placeholder for future)
  # integrated_sgfa_clinical_optimization:
  #   sgfa_performance_metrics:
  #     - "training_time"                     # Basic SGFA timing
  #     - "memory_usage"                      # Memory consumption
  #
  #   pd_subtype_discovery_metrics:
  #     - "subtype_stability_time"            # Time for stable clustering
  #     - "clustering_quality_score"          # Silhouette scores
  #
  #   clinical_translation_metrics:
  #     - "clinical_validation_speed"         # Speed of clinical validation
  #     - "subtype_clinical_separation"       # Clinical difference between subtypes
  #
  #   # Performance-Discovery trade-off analysis (debug version)
  #   trade_off_analysis:
  #     - "speed_vs_subtype_quality"          # SGFA speed vs clustering quality
  #     - "memory_vs_stability"               # Memory usage vs reproducibility

# Reproducibility Experiment - minimal testing
reproducibility:
  test_scenarios:
    - "identical_seeds"                   # Only test identical seeds

  seed_values: [42, 123]                  # Two seeds only
  n_repetitions: 1                        # Single repetition

  convergence_metrics:
    - "factor_correlation"

  tolerance_thresholds:
    correlation_threshold: 0.8            # Relaxed threshold
    parameter_relative_error: 0.1         # Relaxed error tolerance
    reconstruction_error_ratio: 0.05      # Relaxed reconstruction tolerance

# Factor Stability Analysis - DEBUG VERSION (UPDATED for convergence)
factor_stability:
  K: 3                                    # Match debug model K
  num_chains: 3                           # 3 chains (minimum for stability assessment)
  num_samples: 200                        # More samples for convergence (was 50)
  num_warmup: 200                         # More warmup for convergence (was 25)
  chain_method: 'sequential'              # Sequential for easier debugging
  cosine_threshold: 0.8
  min_match_rate: 0.5
  sparsity_threshold: 0.01
  min_nonzero_pct: 0.05
  target_accept_prob: 0.8
  max_tree_depth: 10
  dense_mass: false
  run_pd_subtype_discovery: false         # Skip for fast debugging

  # Comprehensive Factor Analysis Diagnostics
  diagnostics:
    run_all: true                         # Run all diagnostics even in debug mode
    procrustes_alignment:
      disparity_threshold: 0.3
    scale_indeterminacy:
      cv_threshold: 0.3
    slab_saturation:
      saturation_threshold: 0.8
    factor_classification:
      activity_threshold: 0.1

# =============================================================================
# ALTERNATIVE TEST CONFIGURATIONS
# To use these, copy and replace sections above, or create separate config files
# =============================================================================

# ULTRA-FAST CONFIG (for CI/CD or quick smoke tests):
# model:
#   K: 2                                  # Only 2 factors
#   num_samples: 20                       # Only 20 samples
#   num_warmup: 10                        # Only 10 warmup
#   num_chains: 1                         # Single chain
# experiments:
#   run_experiments: ["data_validation"]  # Only run one experiment
#
# MEDIUM SPEED CONFIG (for thorough testing):
# model:
#   K: 5                                  # Medium factors
#   num_samples: 100                      # More samples
#   num_warmup: 50                        # More warmup
# preprocessing:
#   feature_selection_method: "variance"  # Test feature selection
#   variance_threshold: 0.01              # Test thresholding