# SGFA qMAP-PD Configuration File
# Complete configuration with documentation and examples
# See docs/configuration.md for detailed documentation

# =============================================================================
# REQUIRED CONFIGURATION SECTIONS
# =============================================================================

# Data Configuration (REQUIRED)
# Specifies data sources and loading parameters
data:
  data_dir: "./qMAP-PD_data"              # REQUIRED: Path to data directory (must exist)
  clinical_file: "data_clinical/clinical.tsv"  # OPTIONAL: Clinical data file
  volume_dir: "volume_matrices"            # OPTIONAL: Volume matrices directory
  imaging_as_single_view: true            # OPTIONAL: Concatenate all imaging data (default: true)

# Experiment Configuration (REQUIRED)
# Controls experiment execution and output handling
experiments:
  base_output_dir: "./results"            # REQUIRED: Output directory for all results
  save_intermediate: true                 # OPTIONAL: Save intermediate results (default: true)
  generate_plots: true                    # OPTIONAL: Generate visualization plots (default: true)
  enable_spatial_analysis: false         # OPTIONAL: Enable spatial analysis (requires MRI reference, default: true)
  save_pickle_results: false             # OPTIONAL: Save pickle files (can be large, default: false)
  max_parallel_jobs: 2                   # OPTIONAL: Maximum parallel experiments (1-16, default: 1)


# Model Configuration (REQUIRED)
# Defines model type and core hyperparameters
model:
  model_type: "sparse_gfa"               # REQUIRED: "sparse_gfa" or "standard_gfa"
  K: 8                                   # REQUIRED: Number of latent factors (1-50 recommended)

  # MCMC Parameters (OPTIONAL with defaults)
  num_samples: 2000                      # MCMC samples (10-50000, default: 1000)
  num_warmup: 1000                       # MCMC warmup steps (default: 500)
  num_chains: 4                          # MCMC chains (1-8, default: 2)

  # Sparsity Parameters (REQUIRED for sparse_gfa)
  sparsity_lambda: 0.05                  # Sparsity penalty (≥0, typically 0.01-1.0)
  group_lambda: 0.1                      # OPTIONAL: Group sparsity penalty

  # Reproducibility (OPTIONAL)
  random_seed: 42                        # Random seed for reproducible results

# =============================================================================
# OPTIONAL CONFIGURATION SECTIONS (All have sensible defaults)
# =============================================================================

# Preprocessing Configuration (OPTIONAL)
# Controls data preprocessing and feature selection
preprocessing:
  strategy: "standard"                   # "minimal"|"standard"|"advanced"|"clinical_focused"
  enable_advanced_preprocessing: true    # Enable advanced preprocessing pipeline
  enable_spatial_processing: true       # Enable neuroimaging spatial processing
  imputation_strategy: "median"         # "mean"|"median"|"mode"|"drop"
  feature_selection_method: "variance"  # "variance"|"correlation"|"mutual_info"|"none"
  variance_threshold: 0.01              # Remove features with variance < threshold (0.0-1.0)
  missing_threshold: 0.5                # Remove features with >threshold missing (0.0-1.0)

# Cross-Validation Configuration (OPTIONAL)
# Configures model evaluation and validation
cross_validation:
  n_folds: 10                           # Number of CV folds (2-20, recommended: 5-10)
  n_repeats: 3                          # Number of CV repeats (1-10, recommended: 1-3)
  stratified: true                      # Use stratified CV for imbalanced data
  group_aware: false                    # Use group-aware CV for multi-site data
  random_seed: 42                       # Random seed for CV splits

# Monitoring Configuration (OPTIONAL)
# Controls logging, checkpointing, and progress monitoring
monitoring:
  checkpoint_dir: "./results/checkpoints"  # Checkpoint directory
  log_level: "INFO"                     # "DEBUG"|"INFO"|"WARNING"|"ERROR"|"CRITICAL"
  save_checkpoints: true                # Save model checkpoints during training
  checkpoint_interval: 200              # Save checkpoint every N samples (≥1)

# System Configuration (OPTIONAL)
# Hardware and performance optimization settings
system:
  use_gpu: true                         # Use GPU acceleration (default: true)
  memory_limit_gb: 32.0                 # Memory limit in GB (auto-detect if not specified)
  n_cpu_cores: 8                        # Number of CPU cores (auto-detect if not specified)

# =============================================================================
# EXPERIMENT-SPECIFIC CONFIGURATIONS
# =============================================================================

# Data Validation Experiment
data_validation:
  preprocessing_strategies:
    minimal:
      enable_advanced_preprocessing: false
      imputation_strategy: "mean"

    standard:
      enable_advanced_preprocessing: true
      imputation_strategy: "median"
      feature_selection_method: "variance"
      variance_threshold: 0.01

    statistical:
      enable_advanced_preprocessing: true
      imputation_strategy: "median"
      feature_selection_method: "statistical"
      n_top_features: 500

    mutual_info:
      enable_advanced_preprocessing: true
      imputation_strategy: "median"
      feature_selection_method: "mutual_info"
      n_top_features: 500

    combined:
      enable_advanced_preprocessing: true
      imputation_strategy: "median"
      feature_selection_method: "combined"
      n_top_features: 500
      variance_threshold: 0.01

    optimized:
      enable_advanced_preprocessing: true
      optimize_preprocessing: true
      cross_validate_sources: true

    clinical_focused:
      enable_advanced_preprocessing: true
      imputation_strategy: "median"
      feature_selection_method: "statistical"
      n_top_features: 300
      variance_threshold: 0.005           # More stringent for clinical applications

# Method Comparison Experiment
method_comparison:
  models:
    - name: "sparse_gfa"
      n_factors: [5, 8, 10]              # Different factor numbers to test
      sparsity_lambda: [0.01, 0.1, 0.5]  # Different sparsity levels
      group_lambda: [0.1, 0.5]           # Group sparsity options

    - name: "standard_gfa"
      n_factors: [5, 8, 10]              # For comparison with sparse version

  cross_validation:
    n_folds: 5                          # Cross-validation for model comparison
    n_repeats: 2

  evaluation_metrics:
    - "reconstruction_error"            # Model fit quality
    - "factor_interpretability"         # How interpretable are the factors
    - "clinical_correlation"            # Correlation with clinical measures

# Sensitivity Analysis Experiment
sensitivity_analysis:
  parameter_ranges:
    n_factors: [3, 5, 8, 10, 12]        # Range of factor numbers
    sparsity_lambda: [0.01, 0.1, 0.5, 1.0]  # Range of sparsity values
    learning_rate: [0.005, 0.01, 0.05]  # MCMC learning rates

  stability_tests:
    n_random_inits: 5                   # Test stability across random initializations
    convergence_threshold: 1e-5         # Convergence criterion

# Performance Benchmarks Experiment
performance_benchmarks:
  benchmark_configs:
    small_scale:
      n_subjects: 50
      n_features_per_view: [500, 300]   # Small dataset for quick testing

    medium_scale:
      n_subjects: 100
      n_features_per_view: [1000, 800]  # Medium dataset

    full_scale:
      n_subjects: 200
      n_features_per_view: [2000, 1500] # Full dataset size

  # Multi-layer metrics framework
  sgfa_performance_metrics:
    - "training_time"                   # How long does SGFA training take
    - "memory_usage"                    # Peak memory consumption during SGFA
    - "convergence_rate"                # How quickly SGFA converges
    - "factor_extraction_time"          # Time to extract factor scores
    - "mcmc_sampling_efficiency"        # Effective sample size per second

  pd_subtype_discovery_metrics:
    - "subtype_stability_time"          # Time to achieve stable cluster assignments
    - "clinical_validation_speed"       # Speed of clinical correlation analysis
    - "optimal_k_detection_time"        # Time to find optimal number of subtypes
    - "clustering_quality_score"        # Silhouette/Calinski-Harabasz scores
    - "subtype_reproducibility"         # Consistency across random seeds

  clinical_translation_metrics:
    - "factor_interpretability_score"   # Clinical meaningfulness of factors
    - "subtype_clinical_separation"     # Clinical difference between subtypes
    - "biomarker_discovery_efficiency"  # Speed of finding clinical correlates
    - "cross_validation_stability"      # Subtype stability in CV folds

  # Performance-Discovery trade-off analysis
  trade_off_analysis:
    - "speed_vs_subtype_quality"        # SGFA speed impact on subtype quality
    - "memory_vs_stability"             # Memory optimization impact on reproducibility
    - "convergence_vs_clinical_validity" # Fast convergence vs clinical correlation

# Clinical Validation Experiment
clinical_validation:
  validation_types:
    - "pd_subtype_discovery"            # PD subtype discovery using unsupervised clustering
    - "subtype_classification"          # PD subtype prediction (requires predefined labels)
    - "disease_progression"             # Disease progression modeling
    - "biomarker_discovery"             # Novel biomarker identification

  classification_metrics:
    - "accuracy"                        # Classification accuracy
    - "precision"                       # Precision score
    - "recall"                          # Recall score
    - "f1_score"                        # F1 score
    - "roc_auc"                         # ROC AUC

  cross_validation:
    n_folds: 10                         # Robust CV for clinical validation
    stratified: true                    # Maintain class balance

# Reproducibility Experiment
reproducibility:
  test_scenarios:
    - "identical_seeds"                 # Same random seed should give same results
    - "different_hardware"              # Results across different hardware
    - "version_stability"               # Results across software versions

  seed_values: [42, 123, 456, 789]     # Multiple seeds to test
  n_repetitions: 3                     # Repetitions per seed

  convergence_metrics:
    - "factor_correlation"              # Correlation between factor solutions
    - "parameter_stability"             # Stability of model parameters
    - "reconstruction_consistency"      # Consistency of reconstructed data

  tolerance_thresholds:
    correlation_threshold: 0.95         # Minimum correlation for reproducibility
    parameter_relative_error: 0.05      # Maximum relative error in parameters
    reconstruction_error_ratio: 0.02    # Maximum reconstruction error difference

# =============================================================================
# CONFIGURATION EXAMPLES FOR DIFFERENT USE CASES
# =============================================================================

# Example configurations for different scenarios:
#
# DEVELOPMENT (fast testing):
# model:
#   K: 3
#   num_samples: 100
#   num_chains: 1
#
# RESEARCH (balanced performance/quality):
# model:
#   K: 8
#   num_samples: 2000
#   num_chains: 2
#
# PRODUCTION (highest quality):
# model:
#   K: 10
#   num_samples: 5000
#   num_chains: 4
# cross_validation:
#   n_folds: 10
#   n_repeats: 5
#
# HIGH-PERFORMANCE (optimized for speed):
# model:
#   num_samples: 500
#   num_chains: 1
# preprocessing:
#   strategy: "minimal"
# system:
#   use_gpu: true
#   n_cpu_cores: 16